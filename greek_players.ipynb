#!/usr/bin/python3
%matplotlib inline
import requests # This command allows us to fetch URLs
from lxml import html # This module will allow us to parse the returned HTML/XML
import pandas as pd
import MySQLdb as mdb
import matplotlib
import matplotlib.pyplot as plt
from sqlalchemy import create_engine
%matplotlib inline

con = mdb.connect(host = 'localhost', 
                  user = 'root', 
                  passwd = 'dwdstudent2015', 
                  charset='utf8', use_unicode=True);

# Query to create a database
db_name = 'fifa_greek_players'
create_db_query = "CREATE DATABASE IF NOT EXISTS {db} DEFAULT CHARACTER SET 'utf8'".format(db=db_name)

# Create a database
cursor = con.cursor()
cursor.execute(create_db_query)
cursor.close()

# Create the two tables. 
cursor = con.cursor()
table_name = 'Fifa_Greek_players'

create_table_query = '''CREATE TABLE IF NOT EXISTS {db}.{table} 
                                (name varchar(250),
                                age int, 
                                overall int, 
                                potential int,
                                value varchar(250),
                                team varchar(250),
                                PRIMARY KEY(name)
                                )'''.format(db=db_name, table=table_name)
cursor.execute(create_table_query)
cursor.close()

query_template = '''INSERT IGNORE INTO {db}.{table}(name, 
                                            age, 
                                            overall, 
                                            potential, 
                                            value,
                                            team) 
                    VALUES (%s, %s, %s, %s, %s, %s)'''.format(db=db_name, table=table_name)
cursor = con.cursor()

# Let's start by fetching the page, and parsing it
url = "https://sofifa.com/players?na%5B%5D=22"
response = requests.get(url) # get the html of that url
doc = html.fromstring(response.text) # parse it and create a document

articleNodes = doc.xpath("//tr")


def parseArticleNode(article):
    namei=0
    ov=0
    pti=0
    ag=0
    val=0
    tm=0
    name = article.xpath(".//td[2]/div/a[2]//text()")
    for i in name:
        namei = i
    overall = article.xpath(".//td[@id='oa']/div/span//text()")
    for i in overall:
        ov = int(i)
    potential = article.xpath(".//td[@id='pt']/div/span//text()")
    for i in potential:
        pti = int(i)
    age = article.xpath(".//td[@id='ae']/div//text()")
    for i in age:
        ag = int(i.strip())
    age = [int(x.rstrip()) for x in age]        
    value = article.xpath(".//td[@id='vl']/div//text()")
    for i in value:
        val = i
    team = article.xpath(".//td[6]/div/a//text()")
    for i in team:
        tm = i
    
    result = {
        "Name": namei,
        "Age" : ag,
        "Overall" : ov,
        "Potential" : pti,
        "Value" : val,
        "Team" : tm
    }
    query_parameters = (namei, ag, ov, pti,
                        val, tm)
    cursor.execute(query_template, query_parameters)
    print("inserting")
    return result

data = [parseArticleNode(article) for article in articleNodes]
#df = pandas.DataFrame(data)
#df.plot()

con.commit()
cursor.close()

cur = con.cursor(mdb.cursors.DictCursor)
cur.execute("SELECT * FROM {db}.{table}".format(db=db_name, table=table_name))
rows = cur.fetchall()
cur.close()


conn_string_players = 'mysql://{user}:{password}@{host}:{port}/{db}'.format(
    user='root', 
    password='dwdstudent2015', 
    host = 'localhost', 
    port=3306, 
    db='fifa_greek_players'
)
engine_players = create_engine(conn_string_players)

query = '''
SELECT Age, Overall, Potential FROM Fifa_Greek_players
'''
df_players = pd.read_sql(query, con=engine_players)[1:]


df_players.plot()



